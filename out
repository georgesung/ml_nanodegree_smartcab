Simulator.run(): Trial 0
Environment.reset(): Trial set up with start = (4, 2), destination = (4, 6), deadline = 20
RoutePlanner.route_to(): destination = (4, 6)
Net reward: 0, # of penalties: 0
Net reward: 2, # of penalties: 0
Net reward: 3, # of penalties: 0
Net reward: 2, # of penalties: 1
Net reward: 4, # of penalties: 1
Net reward: 5, # of penalties: 1
Net reward: 6, # of penalties: 1
Net reward: 5, # of penalties: 2
Net reward: 4, # of penalties: 3
Net reward: 5, # of penalties: 3
Net reward: 7, # of penalties: 3
Net reward: 8, # of penalties: 3
Net reward: 7, # of penalties: 4
Net reward: 6, # of penalties: 5
Net reward: 5, # of penalties: 6
Net reward: 5, # of penalties: 6
Net reward: 6, # of penalties: 6
Net reward: 7, # of penalties: 6
Net reward: 9, # of penalties: 6
Net reward: 10, # of penalties: 6
Net reward: 9, # of penalties: 7
Environment.reset(): Primary agent could not reach destination within deadline!
Simulator.run(): Trial 1
Environment.reset(): Trial set up with start = (8, 2), destination = (4, 1), deadline = 25
RoutePlanner.route_to(): destination = (4, 1)
Net reward: 1, # of penalties: 0
Net reward: 3, # of penalties: 0
Net reward: 5, # of penalties: 0
Net reward: 6, # of penalties: 0
Net reward: 8, # of penalties: 0
Net reward: 9, # of penalties: 0
Net reward: 10, # of penalties: 0
Net reward: 10, # of penalties: 0
Net reward: 11, # of penalties: 0
Environment.act(): Primary agent has reached destination!
Net reward: 23, # of penalties: 0
Simulator.run(): Trial 2
Environment.reset(): Trial set up with start = (3, 3), destination = (6, 1), deadline = 25
RoutePlanner.route_to(): destination = (6, 1)
Net reward: -1, # of penalties: 1
Net reward: 0, # of penalties: 1
Net reward: 0, # of penalties: 1
Net reward: 0, # of penalties: 1
Net reward: 1, # of penalties: 1
Net reward: 1, # of penalties: 1
Net reward: 3, # of penalties: 1
Net reward: 4, # of penalties: 1
Net reward: 5, # of penalties: 1
Net reward: 4, # of penalties: 2
Net reward: 3, # of penalties: 3
Net reward: 3, # of penalties: 3
Net reward: 5, # of penalties: 3
Net reward: 6, # of penalties: 3
Net reward: 7, # of penalties: 3
Net reward: 6, # of penalties: 4
Net reward: 7, # of penalties: 4
Net reward: 7, # of penalties: 4
Net reward: 6, # of penalties: 5
Net reward: 5, # of penalties: 6
Net reward: 6, # of penalties: 6
Net reward: 5, # of penalties: 7
Net reward: 4, # of penalties: 8
Net reward: 3, # of penalties: 9
Net reward: 3, # of penalties: 9
Net reward: 4, # of penalties: 9
Environment.reset(): Primary agent could not reach destination within deadline!
Simulator.run(): Trial 3
Environment.reset(): Trial set up with start = (3, 2), destination = (6, 3), deadline = 20
RoutePlanner.route_to(): destination = (6, 3)
Net reward: 1, # of penalties: 0
Net reward: 3, # of penalties: 0
Net reward: 3, # of penalties: 0
Net reward: 2, # of penalties: 1
Net reward: 1, # of penalties: 2
Net reward: 2, # of penalties: 2
Net reward: 3, # of penalties: 2
Net reward: 4, # of penalties: 2
Net reward: 4, # of penalties: 2
Net reward: 6, # of penalties: 2
Net reward: 8, # of penalties: 2
Net reward: 9, # of penalties: 2
Net reward: 11, # of penalties: 2
Net reward: 11, # of penalties: 2
Net reward: 10, # of penalties: 3
Net reward: 11, # of penalties: 3
Net reward: 13, # of penalties: 3
Net reward: 15, # of penalties: 3
Net reward: 15, # of penalties: 3
Net reward: 14, # of penalties: 4
Net reward: 15, # of penalties: 4
Environment.reset(): Primary agent could not reach destination within deadline!
Simulator.run(): Trial 4
Environment.reset(): Trial set up with start = (8, 3), destination = (4, 3), deadline = 20
RoutePlanner.route_to(): destination = (4, 3)
Net reward: 2, # of penalties: 0
Net reward: 4, # of penalties: 0
Net reward: 4, # of penalties: 0
Net reward: 5, # of penalties: 0
Net reward: 4, # of penalties: 1
Net reward: 3, # of penalties: 2
Net reward: 2, # of penalties: 3
Net reward: 3, # of penalties: 3
Net reward: 3, # of penalties: 3
Net reward: 4, # of penalties: 3
Net reward: 6, # of penalties: 3
Net reward: 8, # of penalties: 3
Net reward: 9, # of penalties: 3
Net reward: 10, # of penalties: 3
Net reward: 10, # of penalties: 3
Net reward: 9, # of penalties: 4
Net reward: 10, # of penalties: 4
Net reward: 12, # of penalties: 4
Net reward: 11, # of penalties: 5
Net reward: 10, # of penalties: 6
Net reward: 10, # of penalties: 6
Environment.reset(): Primary agent could not reach destination within deadline!
Simulator.run(): Trial 5
Environment.reset(): Trial set up with start = (3, 6), destination = (1, 2), deadline = 30
RoutePlanner.route_to(): destination = (1, 2)
Net reward: 0, # of penalties: 0
Net reward: 1, # of penalties: 0
Net reward: 2, # of penalties: 0
Net reward: 3, # of penalties: 0
Net reward: 5, # of penalties: 0
Net reward: 6, # of penalties: 0
Net reward: 6, # of penalties: 0
Net reward: 7, # of penalties: 0
Net reward: 9, # of penalties: 0
Net reward: 8, # of penalties: 1
Net reward: 9, # of penalties: 1
Net reward: 9, # of penalties: 1
Net reward: 8, # of penalties: 2
Net reward: 7, # of penalties: 3
Net reward: 6, # of penalties: 4
Net reward: 5, # of penalties: 5
Net reward: 6, # of penalties: 5
Net reward: 6, # of penalties: 5
Net reward: 5, # of penalties: 6
Net reward: 7, # of penalties: 6
Net reward: 8, # of penalties: 6
Net reward: 10, # of penalties: 6
Net reward: 10, # of penalties: 6
Net reward: 12, # of penalties: 6
Net reward: 11, # of penalties: 7
Net reward: 10, # of penalties: 8
Net reward: 11, # of penalties: 8
Net reward: 13, # of penalties: 8
Net reward: 12, # of penalties: 9
Net reward: 11, # of penalties: 10
Net reward: 12, # of penalties: 10
Environment.reset(): Primary agent could not reach destination within deadline!
Simulator.run(): Trial 6
Environment.reset(): Trial set up with start = (6, 1), destination = (2, 4), deadline = 35
RoutePlanner.route_to(): destination = (2, 4)
Net reward: 1, # of penalties: 0
Net reward: 0, # of penalties: 1
Net reward: 1, # of penalties: 1
Net reward: 0, # of penalties: 2
Net reward: -1, # of penalties: 3
Net reward: 0, # of penalties: 3
Net reward: 0, # of penalties: 3
Net reward: 2, # of penalties: 3
Net reward: 3, # of penalties: 3
Net reward: 2, # of penalties: 4
Net reward: 1, # of penalties: 5
Net reward: 2, # of penalties: 5
Net reward: 3, # of penalties: 5
Net reward: 5, # of penalties: 5
Net reward: 7, # of penalties: 5
Net reward: 7, # of penalties: 5
Net reward: 9, # of penalties: 5
Net reward: 8, # of penalties: 6
Net reward: 10, # of penalties: 6
Net reward: 11, # of penalties: 6
Net reward: 10, # of penalties: 7
Net reward: 12, # of penalties: 7
Net reward: 13, # of penalties: 7
Net reward: 12, # of penalties: 8
Net reward: 13, # of penalties: 8
Net reward: 14, # of penalties: 8
Net reward: 14, # of penalties: 8
Net reward: 15, # of penalties: 8
Net reward: 16, # of penalties: 8
Net reward: 15, # of penalties: 9
Net reward: 15, # of penalties: 9
Net reward: 16, # of penalties: 9
Net reward: 17, # of penalties: 9
Net reward: 18, # of penalties: 9
Net reward: 19, # of penalties: 9
Net reward: 20, # of penalties: 9
Environment.reset(): Primary agent could not reach destination within deadline!
Simulator.run(): Trial 7
Environment.reset(): Trial set up with start = (1, 1), destination = (4, 4), deadline = 30
RoutePlanner.route_to(): destination = (4, 4)
Net reward: -1, # of penalties: 1
Net reward: -2, # of penalties: 2
Net reward: 0, # of penalties: 2
Net reward: 2, # of penalties: 2
Net reward: 1, # of penalties: 3
Net reward: 3, # of penalties: 3
Net reward: 3, # of penalties: 3
Net reward: 5, # of penalties: 3
Environment.act(): Primary agent has reached destination!
Net reward: 17, # of penalties: 3
Simulator.run(): Trial 8
Environment.reset(): Trial set up with start = (4, 6), destination = (6, 2), deadline = 30
RoutePlanner.route_to(): destination = (6, 2)
Net reward: 2, # of penalties: 0
Net reward: 3, # of penalties: 0
Net reward: 4, # of penalties: 0
Net reward: 3, # of penalties: 1
Net reward: 4, # of penalties: 1
Net reward: 4, # of penalties: 1
Net reward: 5, # of penalties: 1
Net reward: 6, # of penalties: 1
Net reward: 7, # of penalties: 1
Net reward: 9, # of penalties: 1
Net reward: 10, # of penalties: 1
Net reward: 9, # of penalties: 2
Net reward: 8, # of penalties: 3
Net reward: 7, # of penalties: 4
Net reward: 6, # of penalties: 5
Net reward: 7, # of penalties: 5
Net reward: 6, # of penalties: 6
Net reward: 5, # of penalties: 7
Net reward: 4, # of penalties: 8
Net reward: 3, # of penalties: 9
Net reward: 3, # of penalties: 9
Environment.act(): Primary agent has reached destination!
Net reward: 15, # of penalties: 9
Simulator.run(): Trial 9
Environment.reset(): Trial set up with start = (2, 2), destination = (8, 1), deadline = 35
RoutePlanner.route_to(): destination = (8, 1)
Net reward: -1, # of penalties: 1
Net reward: 0, # of penalties: 1
Net reward: 0, # of penalties: 1
Net reward: 2, # of penalties: 1
Net reward: 3, # of penalties: 1
Net reward: 5, # of penalties: 1
Net reward: 7, # of penalties: 1
Net reward: 9, # of penalties: 1
Net reward: 8, # of penalties: 2
Net reward: 7, # of penalties: 3
Net reward: 9, # of penalties: 3
Net reward: 10, # of penalties: 3
Net reward: 9, # of penalties: 4
Net reward: 11, # of penalties: 4
Net reward: 10, # of penalties: 5
Net reward: 11, # of penalties: 5
Net reward: 11, # of penalties: 5
Net reward: 12, # of penalties: 5
Net reward: 13, # of penalties: 5
Net reward: 12, # of penalties: 6
Net reward: 11, # of penalties: 7
Net reward: 11, # of penalties: 7
Net reward: 12, # of penalties: 7
Net reward: 11, # of penalties: 8
Net reward: 11, # of penalties: 8
Net reward: 10, # of penalties: 9
Net reward: 11, # of penalties: 9
Net reward: 10, # of penalties: 10
Net reward: 11, # of penalties: 10
Net reward: 12, # of penalties: 10
Net reward: 12, # of penalties: 10
Net reward: 13, # of penalties: 10
Net reward: 12, # of penalties: 11
Net reward: 13, # of penalties: 11
Net reward: 15, # of penalties: 11
Net reward: 16, # of penalties: 11
Environment.reset(): Primary agent could not reach destination within deadline!
Simulator.run(): Trial 10
Environment.reset(): Trial set up with start = (5, 4), destination = (3, 2), deadline = 20
RoutePlanner.route_to(): destination = (3, 2)
Net reward: 2, # of penalties: 0
Net reward: 3, # of penalties: 0
Net reward: 2, # of penalties: 1
Net reward: 2, # of penalties: 1
Net reward: 3, # of penalties: 1
Net reward: 4, # of penalties: 1
Net reward: 5, # of penalties: 1
Net reward: 7, # of penalties: 1
Net reward: 7, # of penalties: 1
Net reward: 6, # of penalties: 2
Net reward: 7, # of penalties: 2
Net reward: 7, # of penalties: 2
Net reward: 6, # of penalties: 3
Net reward: 8, # of penalties: 3
Net reward: 7, # of penalties: 4
Net reward: 8, # of penalties: 4
Net reward: 8, # of penalties: 4
Net reward: 9, # of penalties: 4
Net reward: 11, # of penalties: 4
Net reward: 10, # of penalties: 5
Net reward: 9, # of penalties: 6
Environment.reset(): Primary agent could not reach destination within deadline!
Simulator.run(): Trial 11
Environment.reset(): Trial set up with start = (7, 6), destination = (5, 4), deadline = 20
RoutePlanner.route_to(): destination = (5, 4)
Net reward: 1, # of penalties: 0
Net reward: 1, # of penalties: 0
Net reward: 2, # of penalties: 0
Net reward: 4, # of penalties: 0
Net reward: 5, # of penalties: 0
Net reward: 5, # of penalties: 0
Net reward: 6, # of penalties: 0
Net reward: 7, # of penalties: 0
Net reward: 7, # of penalties: 0
Net reward: 9, # of penalties: 0
Net reward: 11, # of penalties: 0
Net reward: 12, # of penalties: 0
Net reward: 13, # of penalties: 0
Net reward: 15, # of penalties: 0
Net reward: 15, # of penalties: 0
Net reward: 14, # of penalties: 1
Net reward: 16, # of penalties: 1
Net reward: 18, # of penalties: 1
Net reward: 17, # of penalties: 2
Net reward: 16, # of penalties: 3
Net reward: 17, # of penalties: 3
Environment.reset(): Primary agent could not reach destination within deadline!
Simulator.run(): Trial 12
Environment.reset(): Trial set up with start = (8, 6), destination = (4, 3), deadline = 35
RoutePlanner.route_to(): destination = (4, 3)
Net reward: 1, # of penalties: 0
Net reward: 1, # of penalties: 0
Net reward: 3, # of penalties: 0
Net reward: 5, # of penalties: 0
Net reward: 4, # of penalties: 1
Net reward: 5, # of penalties: 1
Net reward: 5, # of penalties: 1
Net reward: 7, # of penalties: 1
Net reward: 9, # of penalties: 1
Net reward: 10, # of penalties: 1
Net reward: 9, # of penalties: 2
Net reward: 8, # of penalties: 3
Net reward: 9, # of penalties: 3
Net reward: 10, # of penalties: 3
Net reward: 12, # of penalties: 3
Net reward: 13, # of penalties: 3
Net reward: 13, # of penalties: 3
Net reward: 14, # of penalties: 3
Net reward: 13, # of penalties: 4
Net reward: 13, # of penalties: 4
Net reward: 14, # of penalties: 4
Net reward: 15, # of penalties: 4
Net reward: 16, # of penalties: 4
Net reward: 17, # of penalties: 4
Net reward: 19, # of penalties: 4
Net reward: 21, # of penalties: 4
Net reward: 20, # of penalties: 5
Net reward: 21, # of penalties: 5
Net reward: 21, # of penalties: 5
Net reward: 20, # of penalties: 6
Net reward: 21, # of penalties: 6
Net reward: 22, # of penalties: 6
Net reward: 24, # of penalties: 6
Net reward: 24, # of penalties: 6
Net reward: 25, # of penalties: 6
Net reward: 25, # of penalties: 6
Environment.reset(): Primary agent could not reach destination within deadline!
Simulator.run(): Trial 13
Environment.reset(): Trial set up with start = (2, 5), destination = (8, 5), deadline = 30
RoutePlanner.route_to(): destination = (8, 5)
Net reward: 1, # of penalties: 0
Net reward: 1, # of penalties: 0
Net reward: 2, # of penalties: 0
Net reward: 2, # of penalties: 0
Net reward: 3, # of penalties: 0
Net reward: 4, # of penalties: 0
Net reward: 4, # of penalties: 0
Net reward: 6, # of penalties: 0
Net reward: 7, # of penalties: 0
Net reward: 9, # of penalties: 0
Net reward: 10, # of penalties: 0
Net reward: 11, # of penalties: 0
Environment.act(): Primary agent has reached destination!
Net reward: 23, # of penalties: 0
Simulator.run(): Trial 14
Environment.reset(): Trial set up with start = (8, 6), destination = (7, 2), deadline = 25
RoutePlanner.route_to(): destination = (7, 2)
Net reward: 0, # of penalties: 0
Net reward: 1, # of penalties: 0
Net reward: 2, # of penalties: 0
Net reward: 3, # of penalties: 0
Net reward: 4, # of penalties: 0
Net reward: 4, # of penalties: 0
Net reward: 3, # of penalties: 1
Net reward: 2, # of penalties: 2
Net reward: 3, # of penalties: 2
Net reward: 2, # of penalties: 3
Net reward: 3, # of penalties: 3
Net reward: 2, # of penalties: 4
Net reward: 2, # of penalties: 4
Net reward: 1, # of penalties: 5
Net reward: 2, # of penalties: 5
Net reward: 3, # of penalties: 5
Net reward: 3, # of penalties: 5
Net reward: 2, # of penalties: 6
Net reward: 3, # of penalties: 6
Net reward: 4, # of penalties: 6
Net reward: 5, # of penalties: 6
Net reward: 4, # of penalties: 7
Net reward: 5, # of penalties: 7
Net reward: 4, # of penalties: 8
Net reward: 5, # of penalties: 8
Net reward: 5, # of penalties: 8
Environment.reset(): Primary agent could not reach destination within deadline!
Simulator.run(): Trial 15
Environment.reset(): Trial set up with start = (7, 3), destination = (2, 5), deadline = 35
RoutePlanner.route_to(): destination = (2, 5)
Net reward: -1, # of penalties: 1
Net reward: 0, # of penalties: 1
Net reward: -1, # of penalties: 2
Net reward: 0, # of penalties: 2
Net reward: 0, # of penalties: 2
Net reward: 1, # of penalties: 2
Net reward: 2, # of penalties: 2
Net reward: 3, # of penalties: 2
Net reward: 5, # of penalties: 2
Net reward: 4, # of penalties: 3
Net reward: 3, # of penalties: 4
Net reward: 4, # of penalties: 4
Net reward: 6, # of penalties: 4
Net reward: 5, # of penalties: 5
Net reward: 4, # of penalties: 6
Net reward: 6, # of penalties: 6
Net reward: 7, # of penalties: 6
Net reward: 8, # of penalties: 6
Net reward: 9, # of penalties: 6
Net reward: 8, # of penalties: 7
Net reward: 9, # of penalties: 7
Net reward: 11, # of penalties: 7
Net reward: 12, # of penalties: 7
Net reward: 12, # of penalties: 7
Net reward: 13, # of penalties: 7
Net reward: 13, # of penalties: 7
Net reward: 15, # of penalties: 7
Net reward: 14, # of penalties: 8
Net reward: 16, # of penalties: 8
Net reward: 17, # of penalties: 8
Net reward: 18, # of penalties: 8
Net reward: 19, # of penalties: 8
Environment.act(): Primary agent has reached destination!
Net reward: 31, # of penalties: 8
Simulator.run(): Trial 16
Environment.reset(): Trial set up with start = (6, 3), destination = (3, 6), deadline = 30
RoutePlanner.route_to(): destination = (3, 6)
Net reward: -1, # of penalties: 1
Net reward: -2, # of penalties: 2
Net reward: -1, # of penalties: 2
Net reward: 0, # of penalties: 2
Net reward: 1, # of penalties: 2
Net reward: 0, # of penalties: 3
Net reward: 2, # of penalties: 3
Net reward: 3, # of penalties: 3
Net reward: 4, # of penalties: 3
Net reward: 3, # of penalties: 4
Net reward: 2, # of penalties: 5
Net reward: 1, # of penalties: 6
Net reward: 1, # of penalties: 6
Net reward: 0, # of penalties: 7
Net reward: 1, # of penalties: 7
Net reward: 1, # of penalties: 7
Net reward: 2, # of penalties: 7
Net reward: 2, # of penalties: 7
Net reward: 1, # of penalties: 8
Net reward: 2, # of penalties: 8
Net reward: 3, # of penalties: 8
Net reward: 5, # of penalties: 8
Net reward: 6, # of penalties: 8
Net reward: 6, # of penalties: 8
Net reward: 7, # of penalties: 8
Net reward: 9, # of penalties: 8
Net reward: 11, # of penalties: 8
Net reward: 11, # of penalties: 8
Net reward: 10, # of penalties: 9
Net reward: 11, # of penalties: 9
Net reward: 10, # of penalties: 10
Environment.reset(): Primary agent could not reach destination within deadline!
Simulator.run(): Trial 17
Environment.reset(): Trial set up with start = (1, 1), destination = (4, 3), deadline = 25
RoutePlanner.route_to(): destination = (4, 3)
Net reward: 2, # of penalties: 0
Net reward: 4, # of penalties: 0
Net reward: 5, # of penalties: 0
Net reward: 4, # of penalties: 1
Net reward: 4, # of penalties: 1
Net reward: 6, # of penalties: 1
Net reward: 5, # of penalties: 2
Net reward: 6, # of penalties: 2
Net reward: 7, # of penalties: 2
Net reward: 8, # of penalties: 2
Net reward: 8, # of penalties: 2
Net reward: 10, # of penalties: 2
Net reward: 12, # of penalties: 2
Net reward: 11, # of penalties: 3
Net reward: 12, # of penalties: 3
Net reward: 13, # of penalties: 3
Net reward: 14, # of penalties: 3
Net reward: 16, # of penalties: 3
Environment.act(): Primary agent has reached destination!
Net reward: 28, # of penalties: 3
Simulator.run(): Trial 18
Environment.reset(): Trial set up with start = (1, 6), destination = (5, 3), deadline = 35
RoutePlanner.route_to(): destination = (5, 3)
Net reward: 2, # of penalties: 0
Net reward: 3, # of penalties: 0
Net reward: 4, # of penalties: 0
Net reward: 5, # of penalties: 0
Net reward: 7, # of penalties: 0
Net reward: 8, # of penalties: 0
Net reward: 7, # of penalties: 1
Net reward: 8, # of penalties: 1
Net reward: 8, # of penalties: 1
Net reward: 9, # of penalties: 1
Net reward: 8, # of penalties: 2
Net reward: 7, # of penalties: 3
Net reward: 9, # of penalties: 3
Net reward: 11, # of penalties: 3
Net reward: 11, # of penalties: 3
Net reward: 13, # of penalties: 3
Net reward: 14, # of penalties: 3
Net reward: 13, # of penalties: 4
Net reward: 12, # of penalties: 5
Net reward: 11, # of penalties: 6
Net reward: 12, # of penalties: 6
Net reward: 12, # of penalties: 6
Net reward: 13, # of penalties: 6
Net reward: 14, # of penalties: 6
Net reward: 16, # of penalties: 6
Net reward: 17, # of penalties: 6
Net reward: 17, # of penalties: 6
Net reward: 18, # of penalties: 6
Net reward: 17, # of penalties: 7
Net reward: 19, # of penalties: 7
Net reward: 18, # of penalties: 8
Net reward: 17, # of penalties: 9
Net reward: 17, # of penalties: 9
Net reward: 19, # of penalties: 9
Net reward: 21, # of penalties: 9
Net reward: 20, # of penalties: 10
Environment.reset(): Primary agent could not reach destination within deadline!
Simulator.run(): Trial 19
Environment.reset(): Trial set up with start = (1, 1), destination = (2, 5), deadline = 25
RoutePlanner.route_to(): destination = (2, 5)
Net reward: 2, # of penalties: 0
Net reward: 4, # of penalties: 0
Net reward: 6, # of penalties: 0
Net reward: 6, # of penalties: 0
Net reward: 8, # of penalties: 0
Net reward: 10, # of penalties: 0
Net reward: 12, # of penalties: 0
Net reward: 13, # of penalties: 0
Net reward: 14, # of penalties: 0
Net reward: 13, # of penalties: 1
Net reward: 14, # of penalties: 1
Net reward: 15, # of penalties: 1
Net reward: 17, # of penalties: 1
Net reward: 18, # of penalties: 1
Net reward: 17, # of penalties: 2
Net reward: 18, # of penalties: 2
Net reward: 19, # of penalties: 2
Net reward: 19, # of penalties: 2
Net reward: 18, # of penalties: 3
Net reward: 17, # of penalties: 4
Environment.act(): Primary agent has reached destination!
Net reward: 29, # of penalties: 4
Simulator.run(): Trial 20
Environment.reset(): Trial set up with start = (6, 2), destination = (3, 3), deadline = 20
RoutePlanner.route_to(): destination = (3, 3)
Net reward: 0, # of penalties: 0
Net reward: 0, # of penalties: 1
Net reward: 0, # of penalties: 1
Net reward: 2, # of penalties: 1
Net reward: 4, # of penalties: 1
Net reward: 5, # of penalties: 1
Net reward: 6, # of penalties: 1
Net reward: 7, # of penalties: 1
Net reward: 9, # of penalties: 1
Net reward: 8, # of penalties: 2
Net reward: 9, # of penalties: 2
Net reward: 9, # of penalties: 2
Net reward: 10, # of penalties: 2
Net reward: 12, # of penalties: 2
Net reward: 13, # of penalties: 2
Net reward: 15, # of penalties: 2
Net reward: 15, # of penalties: 2
Net reward: 17, # of penalties: 2
Net reward: 18, # of penalties: 2
Net reward: 18, # of penalties: 2
Environment.act(): Primary agent has reached destination!
Net reward: 30, # of penalties: 2
Environment.reset(): Primary agent could not reach destination within deadline!
Simulator.run(): Trial 21
Environment.reset(): Trial set up with start = (1, 3), destination = (7, 6), deadline = 45
RoutePlanner.route_to(): destination = (7, 6)
Net reward: 0, # of penalties: 0
Net reward: 1, # of penalties: 0
Net reward: 2, # of penalties: 0
Net reward: 2, # of penalties: 0
Net reward: 3, # of penalties: 0
Net reward: 5, # of penalties: 0
Net reward: 6, # of penalties: 0
Net reward: 6, # of penalties: 0
Net reward: 7, # of penalties: 0
Net reward: 8, # of penalties: 0
Net reward: 10, # of penalties: 0
Net reward: 11, # of penalties: 0
Net reward: 12, # of penalties: 0
Net reward: 11, # of penalties: 1
Net reward: 12, # of penalties: 1
Net reward: 14, # of penalties: 1
Net reward: 16, # of penalties: 1
Net reward: 17, # of penalties: 1
Net reward: 18, # of penalties: 1
Net reward: 19, # of penalties: 1
Net reward: 20, # of penalties: 1
Net reward: 22, # of penalties: 1
Net reward: 23, # of penalties: 1
Net reward: 22, # of penalties: 2
Net reward: 21, # of penalties: 3
Net reward: 23, # of penalties: 3
Net reward: 25, # of penalties: 3
Net reward: 24, # of penalties: 4
Net reward: 26, # of penalties: 4
Net reward: 26, # of penalties: 4
Net reward: 28, # of penalties: 4
Net reward: 29, # of penalties: 4
Net reward: 29, # of penalties: 4
Environment.act(): Primary agent has reached destination!
Net reward: 41, # of penalties: 4
Simulator.run(): Trial 22
Environment.reset(): Trial set up with start = (7, 1), destination = (6, 4), deadline = 20
RoutePlanner.route_to(): destination = (6, 4)
Net reward: 2, # of penalties: 0
Net reward: 3, # of penalties: 0
Net reward: 2, # of penalties: 1
Net reward: 3, # of penalties: 1
Net reward: 4, # of penalties: 1
Net reward: 6, # of penalties: 1
Net reward: 7, # of penalties: 1
Net reward: 6, # of penalties: 2
Net reward: 7, # of penalties: 2
Net reward: 7, # of penalties: 2
Net reward: 9, # of penalties: 2
Net reward: 11, # of penalties: 2
Net reward: 10, # of penalties: 3
Net reward: 12, # of penalties: 3
Net reward: 11, # of penalties: 4
Net reward: 13, # of penalties: 4
Environment.act(): Primary agent has reached destination!
Net reward: 25, # of penalties: 4
Simulator.run(): Trial 23
Environment.reset(): Trial set up with start = (7, 2), destination = (1, 5), deadline = 45
RoutePlanner.route_to(): destination = (1, 5)
Net reward: 1, # of penalties: 0
Net reward: 2, # of penalties: 0
Net reward: 3, # of penalties: 0
Net reward: 4, # of penalties: 0
Net reward: 6, # of penalties: 0
Net reward: 8, # of penalties: 0
Net reward: 8, # of penalties: 0
Net reward: 7, # of penalties: 1
Net reward: 6, # of penalties: 2
Net reward: 8, # of penalties: 2
Net reward: 10, # of penalties: 2
Net reward: 12, # of penalties: 2
Net reward: 13, # of penalties: 2
Net reward: 14, # of penalties: 2
Net reward: 15, # of penalties: 2
Net reward: 16, # of penalties: 2
Net reward: 18, # of penalties: 2
Net reward: 19, # of penalties: 2
Net reward: 21, # of penalties: 2
Net reward: 21, # of penalties: 2
Net reward: 23, # of penalties: 2
Net reward: 25, # of penalties: 2
Net reward: 26, # of penalties: 2
Net reward: 27, # of penalties: 2
Net reward: 28, # of penalties: 2
Net reward: 27, # of penalties: 3
Net reward: 26, # of penalties: 4
Net reward: 28, # of penalties: 4
Net reward: 29, # of penalties: 4
Net reward: 30, # of penalties: 4
Net reward: 30, # of penalties: 4
Net reward: 29, # of penalties: 5
Net reward: 31, # of penalties: 5
Net reward: 32, # of penalties: 5
Net reward: 31, # of penalties: 6
Net reward: 32, # of penalties: 6
Net reward: 34, # of penalties: 6
Net reward: 36, # of penalties: 6
Net reward: 37, # of penalties: 6
Net reward: 38, # of penalties: 6
Net reward: 40, # of penalties: 6
Net reward: 41, # of penalties: 6
Net reward: 42, # of penalties: 6
Net reward: 44, # of penalties: 6
Net reward: 45, # of penalties: 6
Net reward: 46, # of penalties: 6
Environment.reset(): Primary agent could not reach destination within deadline!
Simulator.run(): Trial 24
Environment.reset(): Trial set up with start = (8, 3), destination = (2, 2), deadline = 35
RoutePlanner.route_to(): destination = (2, 2)
Net reward: 2, # of penalties: 0
Net reward: 1, # of penalties: 1
Net reward: 1, # of penalties: 1
Net reward: 2, # of penalties: 1
Net reward: 3, # of penalties: 1
Net reward: 3, # of penalties: 1
Net reward: 5, # of penalties: 1
Net reward: 7, # of penalties: 1
Net reward: 8, # of penalties: 1
Net reward: 9, # of penalties: 1
Net reward: 10, # of penalties: 1
Net reward: 11, # of penalties: 1
Net reward: 12, # of penalties: 1
Net reward: 13, # of penalties: 1
Net reward: 14, # of penalties: 1
Net reward: 15, # of penalties: 1
Net reward: 17, # of penalties: 1
Net reward: 19, # of penalties: 1
Net reward: 20, # of penalties: 1
Net reward: 21, # of penalties: 1
Net reward: 20, # of penalties: 2
Net reward: 22, # of penalties: 2
Net reward: 23, # of penalties: 2
Net reward: 24, # of penalties: 2
Net reward: 25, # of penalties: 2
Net reward: 25, # of penalties: 2
Net reward: 26, # of penalties: 2
Net reward: 27, # of penalties: 2
Net reward: 26, # of penalties: 3
Net reward: 25, # of penalties: 4
Net reward: 27, # of penalties: 4
Net reward: 28, # of penalties: 4
Net reward: 28, # of penalties: 4
Net reward: 30, # of penalties: 4
Net reward: 32, # of penalties: 4
Net reward: 34, # of penalties: 4
Environment.reset(): Primary agent could not reach destination within deadline!
Simulator.run(): Trial 25
Environment.reset(): Trial set up with start = (3, 2), destination = (6, 5), deadline = 30
RoutePlanner.route_to(): destination = (6, 5)
Net reward: 2, # of penalties: 0
Net reward: 3, # of penalties: 0
Net reward: 4, # of penalties: 0
Net reward: 5, # of penalties: 0
Net reward: 6, # of penalties: 0
Net reward: 8, # of penalties: 0
Net reward: 10, # of penalties: 0
Net reward: 12, # of penalties: 0
Net reward: 13, # of penalties: 0
Net reward: 14, # of penalties: 0
Net reward: 15, # of penalties: 0
Net reward: 15, # of penalties: 0
Net reward: 14, # of penalties: 1
Net reward: 13, # of penalties: 2
Net reward: 14, # of penalties: 2
Net reward: 16, # of penalties: 2
Net reward: 17, # of penalties: 2
Net reward: 19, # of penalties: 2
Net reward: 21, # of penalties: 2
Net reward: 23, # of penalties: 2
Net reward: 25, # of penalties: 2
Net reward: 26, # of penalties: 2
Net reward: 27, # of penalties: 2
Net reward: 28, # of penalties: 2
Net reward: 28, # of penalties: 2
Net reward: 30, # of penalties: 2
Net reward: 32, # of penalties: 2
Net reward: 34, # of penalties: 2
Net reward: 35, # of penalties: 2
Net reward: 36, # of penalties: 2
Net reward: 38, # of penalties: 2
Environment.reset(): Primary agent could not reach destination within deadline!
Simulator.run(): Trial 26
Environment.reset(): Trial set up with start = (4, 3), destination = (2, 5), deadline = 20
RoutePlanner.route_to(): destination = (2, 5)
Net reward: -1, # of penalties: 1
Net reward: 0, # of penalties: 1
Net reward: 1, # of penalties: 1
Net reward: 2, # of penalties: 1
Net reward: 2, # of penalties: 1
Net reward: 4, # of penalties: 1
Net reward: 6, # of penalties: 1
Net reward: 7, # of penalties: 1
Net reward: 8, # of penalties: 1
Net reward: 10, # of penalties: 1
Net reward: 11, # of penalties: 1
Net reward: 12, # of penalties: 1
Net reward: 13, # of penalties: 1
Environment.act(): Primary agent has reached destination!
Net reward: 25, # of penalties: 1
Simulator.run(): Trial 27
Environment.reset(): Trial set up with start = (1, 3), destination = (3, 1), deadline = 20
RoutePlanner.route_to(): destination = (3, 1)
Net reward: 2, # of penalties: 0
Net reward: 1, # of penalties: 1
Net reward: 0, # of penalties: 2
Net reward: 1, # of penalties: 2
Net reward: 3, # of penalties: 2
Net reward: 3, # of penalties: 2
Net reward: 4, # of penalties: 2
Net reward: 6, # of penalties: 2
Net reward: 8, # of penalties: 2
Net reward: 9, # of penalties: 2
Net reward: 11, # of penalties: 2
Net reward: 12, # of penalties: 2
Net reward: 14, # of penalties: 2
Net reward: 16, # of penalties: 2
Net reward: 18, # of penalties: 2
Net reward: 20, # of penalties: 2
Net reward: 21, # of penalties: 2
Net reward: 20, # of penalties: 3
Environment.act(): Primary agent has reached destination!
Net reward: 32, # of penalties: 3
Simulator.run(): Trial 28
Environment.reset(): Trial set up with start = (6, 6), destination = (7, 3), deadline = 20
RoutePlanner.route_to(): destination = (7, 3)
Net reward: 1, # of penalties: 0
Net reward: 0, # of penalties: 1
Net reward: -1, # of penalties: 2
Net reward: 0, # of penalties: 2
Net reward: 2, # of penalties: 2
Net reward: 3, # of penalties: 2
Net reward: 5, # of penalties: 2
Net reward: 6, # of penalties: 2
Net reward: 7, # of penalties: 2
Net reward: 8, # of penalties: 2
Net reward: 10, # of penalties: 2
Environment.act(): Primary agent has reached destination!
Net reward: 22, # of penalties: 2
Simulator.run(): Trial 29
Environment.reset(): Trial set up with start = (1, 3), destination = (6, 6), deadline = 40
RoutePlanner.route_to(): destination = (6, 6)
Net reward: 0, # of penalties: 0
Net reward: 2, # of penalties: 0
Net reward: 3, # of penalties: 0
Net reward: 4, # of penalties: 0
Net reward: 5, # of penalties: 0
Net reward: 7, # of penalties: 0
Net reward: 9, # of penalties: 0
Net reward: 11, # of penalties: 0
Net reward: 12, # of penalties: 0
Net reward: 14, # of penalties: 0
Net reward: 16, # of penalties: 0
Net reward: 17, # of penalties: 0
Net reward: 19, # of penalties: 0
Net reward: 20, # of penalties: 0
Net reward: 22, # of penalties: 0
Net reward: 24, # of penalties: 0
Net reward: 26, # of penalties: 0
Net reward: 28, # of penalties: 0
Net reward: 29, # of penalties: 0
Net reward: 29, # of penalties: 0
Net reward: 31, # of penalties: 0
Net reward: 33, # of penalties: 0
Net reward: 35, # of penalties: 0
Net reward: 36, # of penalties: 0
Environment.act(): Primary agent has reached destination!
Net reward: 48, # of penalties: 0
Simulator.run(): Trial 30
Environment.reset(): Trial set up with start = (8, 6), destination = (3, 5), deadline = 30
RoutePlanner.route_to(): destination = (3, 5)
Net reward: 2, # of penalties: 0
Net reward: 3, # of penalties: 0
Net reward: 4, # of penalties: 0
Net reward: 6, # of penalties: 0
Net reward: 8, # of penalties: 0
Net reward: 9, # of penalties: 0
Net reward: 10, # of penalties: 0
Net reward: 11, # of penalties: 0
Net reward: 13, # of penalties: 0
Net reward: 15, # of penalties: 0
Environment.act(): Primary agent has reached destination!
Net reward: 27, # of penalties: 0
Simulator.run(): Trial 31
Environment.reset(): Trial set up with start = (8, 3), destination = (4, 1), deadline = 30
RoutePlanner.route_to(): destination = (4, 1)
Net reward: 1, # of penalties: 0
Net reward: 2, # of penalties: 0
Net reward: 3, # of penalties: 0
Net reward: 5, # of penalties: 0
Net reward: 7, # of penalties: 0
Net reward: 8, # of penalties: 0
Net reward: 9, # of penalties: 0
Net reward: 10, # of penalties: 0
Net reward: 11, # of penalties: 0
Net reward: 13, # of penalties: 0
Net reward: 15, # of penalties: 0
Net reward: 17, # of penalties: 0
Net reward: 18, # of penalties: 0
Net reward: 19, # of penalties: 0
Net reward: 20, # of penalties: 0
Net reward: 21, # of penalties: 0
Environment.act(): Primary agent has reached destination!
Net reward: 33, # of penalties: 0
Simulator.run(): Trial 32
Environment.reset(): Trial set up with start = (3, 1), destination = (3, 5), deadline = 20
RoutePlanner.route_to(): destination = (3, 5)
Net reward: 1, # of penalties: 0
Net reward: 2, # of penalties: 0
Net reward: 3, # of penalties: 0
Net reward: 4, # of penalties: 0
Net reward: 6, # of penalties: 0
Net reward: 8, # of penalties: 0
Net reward: 9, # of penalties: 0
Net reward: 10, # of penalties: 0
Net reward: 10, # of penalties: 0
Net reward: 12, # of penalties: 0
Net reward: 14, # of penalties: 0
Net reward: 16, # of penalties: 0
Net reward: 17, # of penalties: 0
Net reward: 18, # of penalties: 0
Net reward: 19, # of penalties: 0
Net reward: 21, # of penalties: 0
Net reward: 22, # of penalties: 0
Net reward: 23, # of penalties: 0
Net reward: 24, # of penalties: 0
Net reward: 25, # of penalties: 0
Net reward: 26, # of penalties: 0
Environment.reset(): Primary agent could not reach destination within deadline!
Simulator.run(): Trial 33
Environment.reset(): Trial set up with start = (3, 1), destination = (5, 5), deadline = 30
RoutePlanner.route_to(): destination = (5, 5)
Net reward: 2, # of penalties: 0
Net reward: 4, # of penalties: 0
Net reward: 6, # of penalties: 0
Net reward: 7, # of penalties: 0
Environment.act(): Primary agent has reached destination!
Net reward: 19, # of penalties: 0
Simulator.run(): Trial 34
Environment.reset(): Trial set up with start = (3, 4), destination = (8, 3), deadline = 30
RoutePlanner.route_to(): destination = (8, 3)
Net reward: 1, # of penalties: 0
Net reward: 2, # of penalties: 0
Net reward: 3, # of penalties: 0
Net reward: 4, # of penalties: 0
Net reward: 6, # of penalties: 0
Net reward: 8, # of penalties: 0
Net reward: 8, # of penalties: 0
Net reward: 10, # of penalties: 0
Net reward: 12, # of penalties: 0
Net reward: 13, # of penalties: 0
Net reward: 14, # of penalties: 0
Net reward: 15, # of penalties: 0
Environment.act(): Primary agent has reached destination!
Net reward: 27, # of penalties: 0
Simulator.run(): Trial 35
Environment.reset(): Trial set up with start = (8, 5), destination = (3, 2), deadline = 40
RoutePlanner.route_to(): destination = (3, 2)
Net reward: 1, # of penalties: 0
Net reward: 2, # of penalties: 0
Net reward: 3, # of penalties: 0
Net reward: 4, # of penalties: 0
Net reward: 5, # of penalties: 0
Net reward: 7, # of penalties: 0
Net reward: 9, # of penalties: 0
Net reward: 11, # of penalties: 0
Net reward: 12, # of penalties: 0
Net reward: 13, # of penalties: 0
Net reward: 14, # of penalties: 0
Net reward: 15, # of penalties: 0
Net reward: 17, # of penalties: 0
Net reward: 19, # of penalties: 0
Net reward: 21, # of penalties: 0
Net reward: 22, # of penalties: 0
Net reward: 24, # of penalties: 0
Net reward: 25, # of penalties: 0
Environment.act(): Primary agent has reached destination!
Net reward: 37, # of penalties: 0
Simulator.run(): Trial 36
Environment.reset(): Trial set up with start = (4, 5), destination = (3, 1), deadline = 25
RoutePlanner.route_to(): destination = (3, 1)
Net reward: 1, # of penalties: 0
Net reward: 2, # of penalties: 0
Net reward: 3, # of penalties: 0
Net reward: 4, # of penalties: 0
Net reward: 3, # of penalties: 1
Net reward: 5, # of penalties: 1
Net reward: 7, # of penalties: 1
Net reward: 8, # of penalties: 1
Net reward: 10, # of penalties: 1
Net reward: 11, # of penalties: 1
Net reward: 12, # of penalties: 1
Net reward: 13, # of penalties: 1
Net reward: 13, # of penalties: 1
Net reward: 15, # of penalties: 1
Net reward: 17, # of penalties: 1
Net reward: 19, # of penalties: 1
Net reward: 20, # of penalties: 1
Net reward: 21, # of penalties: 1
Net reward: 23, # of penalties: 1
Environment.act(): Primary agent has reached destination!
Net reward: 35, # of penalties: 1
Simulator.run(): Trial 37
Environment.reset(): Trial set up with start = (3, 2), destination = (8, 4), deadline = 35
RoutePlanner.route_to(): destination = (8, 4)
Net reward: 2, # of penalties: 0
Net reward: 4, # of penalties: 0
Net reward: 6, # of penalties: 0
Net reward: 8, # of penalties: 0
Net reward: 9, # of penalties: 0
Net reward: 10, # of penalties: 0
Net reward: 11, # of penalties: 0
Net reward: 12, # of penalties: 0
Net reward: 14, # of penalties: 0
Net reward: 16, # of penalties: 0
Environment.act(): Primary agent has reached destination!
Net reward: 28, # of penalties: 0
Simulator.run(): Trial 38
Environment.reset(): Trial set up with start = (2, 6), destination = (6, 2), deadline = 40
RoutePlanner.route_to(): destination = (6, 2)
Net reward: 1, # of penalties: 0
Net reward: 2, # of penalties: 0
Net reward: 3, # of penalties: 0
Net reward: 4, # of penalties: 0
Net reward: 5, # of penalties: 0
Net reward: 7, # of penalties: 0
Net reward: 8, # of penalties: 0
Net reward: 9, # of penalties: 0
Net reward: 10, # of penalties: 0
Net reward: 11, # of penalties: 0
Net reward: 13, # of penalties: 0
Net reward: 15, # of penalties: 0
Net reward: 17, # of penalties: 0
Net reward: 18, # of penalties: 0
Net reward: 19, # of penalties: 0
Net reward: 20, # of penalties: 0
Net reward: 22, # of penalties: 0
Net reward: 23, # of penalties: 0
Net reward: 25, # of penalties: 0
Net reward: 26, # of penalties: 0
Net reward: 28, # of penalties: 0
Net reward: 29, # of penalties: 0
Net reward: 30, # of penalties: 0
Net reward: 31, # of penalties: 0
Environment.act(): Primary agent has reached destination!
Net reward: 43, # of penalties: 0
Simulator.run(): Trial 39
Environment.reset(): Trial set up with start = (8, 1), destination = (3, 3), deadline = 35
RoutePlanner.route_to(): destination = (3, 3)
Net reward: 2, # of penalties: 0
Net reward: 4, # of penalties: 0
Net reward: 6, # of penalties: 0
Net reward: 8, # of penalties: 0
Net reward: 10, # of penalties: 0
Net reward: 12, # of penalties: 0
Net reward: 13, # of penalties: 0
Net reward: 14, # of penalties: 0
Net reward: 15, # of penalties: 0
Environment.act(): Primary agent has reached destination!
Net reward: 27, # of penalties: 0
Simulator.run(): Trial 40
Environment.reset(): Trial set up with start = (2, 3), destination = (5, 2), deadline = 20
RoutePlanner.route_to(): destination = (5, 2)
Net reward: 2, # of penalties: 0
Net reward: 3, # of penalties: 0
Net reward: 4, # of penalties: 0
Net reward: 6, # of penalties: 0
Net reward: 7, # of penalties: 0
Net reward: 8, # of penalties: 0
Net reward: 9, # of penalties: 0
Net reward: 10, # of penalties: 0
Net reward: 12, # of penalties: 0
Net reward: 13, # of penalties: 0
Environment.act(): Primary agent has reached destination!
Net reward: 25, # of penalties: 0
Simulator.run(): Trial 41
Environment.reset(): Trial set up with start = (7, 6), destination = (5, 3), deadline = 25
RoutePlanner.route_to(): destination = (5, 3)
Net reward: 2, # of penalties: 0
Net reward: 3, # of penalties: 0
Net reward: 5, # of penalties: 0
Net reward: 7, # of penalties: 0
Net reward: 8, # of penalties: 0
Net reward: 9, # of penalties: 0
Net reward: 10, # of penalties: 0
Net reward: 11, # of penalties: 0
Net reward: 13, # of penalties: 0
Environment.act(): Primary agent has reached destination!
Net reward: 25, # of penalties: 0
Simulator.run(): Trial 42
Environment.reset(): Trial set up with start = (4, 3), destination = (1, 6), deadline = 30
RoutePlanner.route_to(): destination = (1, 6)
Net reward: 1, # of penalties: 0
Net reward: 0, # of penalties: 1
Net reward: 1, # of penalties: 1
Net reward: 2, # of penalties: 1
Net reward: 4, # of penalties: 1
Net reward: 6, # of penalties: 1
Net reward: 7, # of penalties: 1
Net reward: 8, # of penalties: 1
Net reward: 10, # of penalties: 1
Net reward: 11, # of penalties: 1
Net reward: 13, # of penalties: 1
Net reward: 14, # of penalties: 1
Net reward: 14, # of penalties: 1
Net reward: 15, # of penalties: 1
Net reward: 16, # of penalties: 1
Net reward: 18, # of penalties: 1
Net reward: 19, # of penalties: 1
Net reward: 20, # of penalties: 1
Net reward: 21, # of penalties: 1
Net reward: 22, # of penalties: 1
Net reward: 24, # of penalties: 1
Net reward: 26, # of penalties: 1
Net reward: 27, # of penalties: 1
Net reward: 28, # of penalties: 1
Net reward: 29, # of penalties: 1
Net reward: 31, # of penalties: 1
Net reward: 33, # of penalties: 1
Net reward: 35, # of penalties: 1
Net reward: 36, # of penalties: 1
Net reward: 37, # of penalties: 1
Net reward: 38, # of penalties: 1
Environment.reset(): Primary agent could not reach destination within deadline!
Simulator.run(): Trial 43
Environment.reset(): Trial set up with start = (4, 2), destination = (6, 5), deadline = 25
RoutePlanner.route_to(): destination = (6, 5)
Net reward: 2, # of penalties: 0
Net reward: 4, # of penalties: 0
Net reward: 6, # of penalties: 0
Net reward: 7, # of penalties: 0
Net reward: 9, # of penalties: 0
Net reward: 10, # of penalties: 0
Net reward: 11, # of penalties: 0
Net reward: 12, # of penalties: 0
Net reward: 13, # of penalties: 0
Net reward: 14, # of penalties: 0
Environment.act(): Primary agent has reached destination!
Net reward: 26, # of penalties: 0
Simulator.run(): Trial 44
Environment.reset(): Trial set up with start = (2, 2), destination = (5, 1), deadline = 20
RoutePlanner.route_to(): destination = (5, 1)
Net reward: 1, # of penalties: 0
Net reward: 2, # of penalties: 0
Net reward: 3, # of penalties: 0
Net reward: 4, # of penalties: 0
Net reward: 5, # of penalties: 0
Net reward: 7, # of penalties: 0
Net reward: 9, # of penalties: 0
Net reward: 11, # of penalties: 0
Net reward: 12, # of penalties: 0
Environment.act(): Primary agent has reached destination!
Net reward: 24, # of penalties: 0
Simulator.run(): Trial 45
Environment.reset(): Trial set up with start = (2, 6), destination = (3, 3), deadline = 20
RoutePlanner.route_to(): destination = (3, 3)
Net reward: 2, # of penalties: 0
Net reward: 3, # of penalties: 0
Net reward: 5, # of penalties: 0
Net reward: 6, # of penalties: 0
Net reward: 7, # of penalties: 0
Net reward: 8, # of penalties: 0
Net reward: 10, # of penalties: 0
Environment.act(): Primary agent has reached destination!
Net reward: 22, # of penalties: 0
Simulator.run(): Trial 46
Environment.reset(): Trial set up with start = (7, 6), destination = (6, 2), deadline = 25
RoutePlanner.route_to(): destination = (6, 2)
Net reward: 2, # of penalties: 0
Net reward: 4, # of penalties: 0
Environment.act(): Primary agent has reached destination!
Net reward: 16, # of penalties: 0
Simulator.run(): Trial 47
Environment.reset(): Trial set up with start = (2, 4), destination = (8, 1), deadline = 45
RoutePlanner.route_to(): destination = (8, 1)
Net reward: 2, # of penalties: 0
Net reward: 3, # of penalties: 0
Net reward: 4, # of penalties: 0
Net reward: 5, # of penalties: 0
Net reward: 7, # of penalties: 0
Net reward: 9, # of penalties: 0
Net reward: 11, # of penalties: 0
Net reward: 13, # of penalties: 0
Net reward: 15, # of penalties: 0
Net reward: 17, # of penalties: 0
Net reward: 19, # of penalties: 0
Environment.act(): Primary agent has reached destination!
Net reward: 31, # of penalties: 0
Simulator.run(): Trial 48
Environment.reset(): Trial set up with start = (3, 6), destination = (7, 2), deadline = 40
RoutePlanner.route_to(): destination = (7, 2)
Net reward: 1, # of penalties: 0
Net reward: 2, # of penalties: 0
Net reward: 3, # of penalties: 0
Net reward: 4, # of penalties: 0
Net reward: 5, # of penalties: 0
Net reward: 7, # of penalties: 0
Net reward: 8, # of penalties: 0
Net reward: 9, # of penalties: 0
Net reward: 10, # of penalties: 0
Net reward: 11, # of penalties: 0
Net reward: 13, # of penalties: 0
Net reward: 14, # of penalties: 0
Net reward: 16, # of penalties: 0
Net reward: 17, # of penalties: 0
Net reward: 18, # of penalties: 0
Net reward: 19, # of penalties: 0
Net reward: 21, # of penalties: 0
Net reward: 23, # of penalties: 0
Net reward: 25, # of penalties: 0
Net reward: 27, # of penalties: 0
Environment.act(): Primary agent has reached destination!
Net reward: 39, # of penalties: 0
Simulator.run(): Trial 49
Environment.reset(): Trial set up with start = (7, 3), destination = (3, 5), deadline = 30
RoutePlanner.route_to(): destination = (3, 5)
Net reward: 2, # of penalties: 0
Net reward: 4, # of penalties: 0
Net reward: 5, # of penalties: 0
Net reward: 6, # of penalties: 0
Net reward: 7, # of penalties: 0
Net reward: 9, # of penalties: 0
Net reward: 11, # of penalties: 0
Net reward: 13, # of penalties: 0
Net reward: 14, # of penalties: 0
Net reward: 14, # of penalties: 0
Net reward: 16, # of penalties: 0
Net reward: 18, # of penalties: 0
Net reward: 19, # of penalties: 0
Net reward: 20, # of penalties: 0
Net reward: 21, # of penalties: 0
Net reward: 23, # of penalties: 0
Net reward: 24, # of penalties: 0
Net reward: 25, # of penalties: 0
Net reward: 26, # of penalties: 0
Net reward: 27, # of penalties: 0
Environment.act(): Primary agent has reached destination!
Net reward: 39, # of penalties: 0
Simulator.run(): Trial 50
Environment.reset(): Trial set up with start = (5, 1), destination = (5, 5), deadline = 20
RoutePlanner.route_to(): destination = (5, 5)
Net reward: 1, # of penalties: 0
Net reward: 2, # of penalties: 0
Net reward: 3, # of penalties: 0
Net reward: 5, # of penalties: 0
Net reward: 6, # of penalties: 0
Net reward: 7, # of penalties: 0
Net reward: 9, # of penalties: 0
Net reward: 10, # of penalties: 0
Net reward: 11, # of penalties: 0
Net reward: 12, # of penalties: 0
Net reward: 14, # of penalties: 0
Environment.act(): Primary agent has reached destination!
Net reward: 26, # of penalties: 0
Simulator.run(): Trial 51
Environment.reset(): Trial set up with start = (3, 6), destination = (7, 4), deadline = 30
RoutePlanner.route_to(): destination = (7, 4)
Net reward: 2, # of penalties: 0
Net reward: 4, # of penalties: 0
Net reward: 5, # of penalties: 0
Net reward: 6, # of penalties: 0
Net reward: 8, # of penalties: 0
Net reward: 9, # of penalties: 0
Net reward: 10, # of penalties: 0
Net reward: 11, # of penalties: 0
Net reward: 13, # of penalties: 0
Net reward: 14, # of penalties: 0
Net reward: 15, # of penalties: 0
Net reward: 16, # of penalties: 0
Net reward: 18, # of penalties: 0
Net reward: 19, # of penalties: 0
Net reward: 20, # of penalties: 0
Environment.act(): Primary agent has reached destination!
Net reward: 32, # of penalties: 0
Simulator.run(): Trial 52
Environment.reset(): Trial set up with start = (4, 3), destination = (1, 1), deadline = 25
RoutePlanner.route_to(): destination = (1, 1)
Net reward: 2, # of penalties: 0
Net reward: 4, # of penalties: 0
Net reward: 5, # of penalties: 0
Net reward: 6, # of penalties: 0
Net reward: 8, # of penalties: 0
Net reward: 10, # of penalties: 0
Environment.act(): Primary agent has reached destination!
Net reward: 22, # of penalties: 0
Simulator.run(): Trial 53
Environment.reset(): Trial set up with start = (2, 5), destination = (4, 2), deadline = 25
RoutePlanner.route_to(): destination = (4, 2)
Net reward: 2, # of penalties: 0
Net reward: 4, # of penalties: 0
Net reward: 5, # of penalties: 0
Net reward: 6, # of penalties: 0
Net reward: 8, # of penalties: 0
Net reward: 9, # of penalties: 0
Net reward: 11, # of penalties: 0
Environment.act(): Primary agent has reached destination!
Net reward: 23, # of penalties: 0
Simulator.run(): Trial 54
Environment.reset(): Trial set up with start = (2, 5), destination = (6, 4), deadline = 25
RoutePlanner.route_to(): destination = (6, 4)
Net reward: 1, # of penalties: 0
Net reward: 2, # of penalties: 0
Net reward: 3, # of penalties: 0
Net reward: 5, # of penalties: 0
Net reward: 7, # of penalties: 0
Net reward: 9, # of penalties: 0
Net reward: 10, # of penalties: 0
Net reward: 11, # of penalties: 0
Net reward: 13, # of penalties: 0
Environment.act(): Primary agent has reached destination!
Net reward: 25, # of penalties: 0
Simulator.run(): Trial 55
Environment.reset(): Trial set up with start = (7, 3), destination = (3, 1), deadline = 30
RoutePlanner.route_to(): destination = (3, 1)
Net reward: 1, # of penalties: 0
Net reward: 2, # of penalties: 0
Net reward: 3, # of penalties: 0
Net reward: 4, # of penalties: 0
Net reward: 6, # of penalties: 0
Net reward: 7, # of penalties: 0
Net reward: 8, # of penalties: 0
Net reward: 9, # of penalties: 0
Net reward: 11, # of penalties: 0
Net reward: 13, # of penalties: 0
Net reward: 14, # of penalties: 0
Net reward: 15, # of penalties: 0
Net reward: 17, # of penalties: 0
Net reward: 19, # of penalties: 0
Environment.act(): Primary agent has reached destination!
Net reward: 31, # of penalties: 0
Simulator.run(): Trial 56
Environment.reset(): Trial set up with start = (8, 2), destination = (3, 6), deadline = 45
RoutePlanner.route_to(): destination = (3, 6)
Net reward: 2, # of penalties: 0
Net reward: 4, # of penalties: 0
Net reward: 5, # of penalties: 0
Net reward: 7, # of penalties: 0
Net reward: 8, # of penalties: 0
Net reward: 9, # of penalties: 0
Net reward: 11, # of penalties: 0
Net reward: 12, # of penalties: 0
Net reward: 14, # of penalties: 0
Net reward: 16, # of penalties: 0
Net reward: 17, # of penalties: 0
Net reward: 18, # of penalties: 0
Net reward: 20, # of penalties: 0
Net reward: 21, # of penalties: 0
Net reward: 22, # of penalties: 0
Net reward: 23, # of penalties: 0
Net reward: 25, # of penalties: 0
Environment.act(): Primary agent has reached destination!
Net reward: 37, # of penalties: 0
Simulator.run(): Trial 57
Environment.reset(): Trial set up with start = (4, 4), destination = (3, 1), deadline = 20
RoutePlanner.route_to(): destination = (3, 1)
Net reward: 2, # of penalties: 0
Net reward: 4, # of penalties: 0
Net reward: 5, # of penalties: 0
Net reward: 7, # of penalties: 0
Environment.act(): Primary agent has reached destination!
Net reward: 19, # of penalties: 0
Simulator.run(): Trial 58
Environment.reset(): Trial set up with start = (6, 3), destination = (2, 5), deadline = 30
RoutePlanner.route_to(): destination = (2, 5)
Net reward: 2, # of penalties: 0
Net reward: 4, # of penalties: 0
Net reward: 5, # of penalties: 0
Net reward: 6, # of penalties: 0
Net reward: 8, # of penalties: 0
Net reward: 10, # of penalties: 0
Net reward: 12, # of penalties: 0
Environment.act(): Primary agent has reached destination!
Net reward: 24, # of penalties: 0
Simulator.run(): Trial 59
Environment.reset(): Trial set up with start = (2, 4), destination = (6, 4), deadline = 20
RoutePlanner.route_to(): destination = (6, 4)
Net reward: 2, # of penalties: 0
Net reward: 3, # of penalties: 0
Net reward: 4, # of penalties: 0
Net reward: 5, # of penalties: 0
Net reward: 7, # of penalties: 0
Net reward: 9, # of penalties: 0
Environment.act(): Primary agent has reached destination!
Net reward: 21, # of penalties: 0
Simulator.run(): Trial 60
Environment.reset(): Trial set up with start = (7, 6), destination = (6, 1), deadline = 30
RoutePlanner.route_to(): destination = (6, 1)
Net reward: 1, # of penalties: 0
Net reward: 2, # of penalties: 0
Net reward: 3, # of penalties: 0
Net reward: 5, # of penalties: 0
Net reward: 7, # of penalties: 0
Net reward: 9, # of penalties: 0
Net reward: 11, # of penalties: 0
Net reward: 13, # of penalties: 0
Environment.act(): Primary agent has reached destination!
Net reward: 25, # of penalties: 0
Simulator.run(): Trial 61
Environment.reset(): Trial set up with start = (7, 1), destination = (3, 5), deadline = 40
RoutePlanner.route_to(): destination = (3, 5)
Net reward: 1, # of penalties: 0
Net reward: 2, # of penalties: 0
Net reward: 3, # of penalties: 0
Net reward: 4, # of penalties: 0
Net reward: 6, # of penalties: 0
Net reward: 5, # of penalties: 1
Net reward: 6, # of penalties: 1
Net reward: 7, # of penalties: 1
Net reward: 8, # of penalties: 1
Net reward: 9, # of penalties: 1
Net reward: 9, # of penalties: 1
Net reward: 11, # of penalties: 1
Net reward: 12, # of penalties: 1
Net reward: 13, # of penalties: 1
Net reward: 14, # of penalties: 1
Net reward: 15, # of penalties: 1
Net reward: 17, # of penalties: 1
Net reward: 18, # of penalties: 1
Net reward: 19, # of penalties: 1
Net reward: 20, # of penalties: 1
Net reward: 22, # of penalties: 1
Environment.act(): Primary agent has reached destination!
Net reward: 34, # of penalties: 1
Simulator.run(): Trial 62
Environment.reset(): Trial set up with start = (6, 1), destination = (6, 6), deadline = 25
RoutePlanner.route_to(): destination = (6, 6)
Net reward: 2, # of penalties: 0
Net reward: 3, # of penalties: 0
Net reward: 4, # of penalties: 0
Net reward: 6, # of penalties: 0
Net reward: 7, # of penalties: 0
Net reward: 8, # of penalties: 0
Net reward: 9, # of penalties: 0
Net reward: 10, # of penalties: 0
Net reward: 12, # of penalties: 0
Net reward: 13, # of penalties: 0
Net reward: 15, # of penalties: 0
Net reward: 16, # of penalties: 0
Environment.act(): Primary agent has reached destination!
Net reward: 28, # of penalties: 0
Simulator.run(): Trial 63
Environment.reset(): Trial set up with start = (8, 6), destination = (6, 2), deadline = 30
RoutePlanner.route_to(): destination = (6, 2)
Net reward: 2, # of penalties: 0
Net reward: 3, # of penalties: 0
Net reward: 4, # of penalties: 0
Net reward: 6, # of penalties: 0
Net reward: 8, # of penalties: 0
Net reward: 9, # of penalties: 0
Net reward: 11, # of penalties: 0
Net reward: 12, # of penalties: 0
Net reward: 13, # of penalties: 0
Net reward: 14, # of penalties: 0
Net reward: 16, # of penalties: 0
Net reward: 17, # of penalties: 0
Environment.act(): Primary agent has reached destination!
Net reward: 29, # of penalties: 0
Simulator.run(): Trial 64
Environment.reset(): Trial set up with start = (6, 1), destination = (3, 6), deadline = 40
RoutePlanner.route_to(): destination = (3, 6)
Net reward: 2, # of penalties: 0
Net reward: 4, # of penalties: 0
Net reward: 5, # of penalties: 0
Net reward: 7, # of penalties: 0
Net reward: 8, # of penalties: 0
Net reward: 9, # of penalties: 0
Net reward: 10, # of penalties: 0
Net reward: 11, # of penalties: 0
Net reward: 13, # of penalties: 0
Net reward: 14, # of penalties: 0
Net reward: 15, # of penalties: 0
Net reward: 16, # of penalties: 0
Net reward: 18, # of penalties: 0
Net reward: 19, # of penalties: 0
Net reward: 20, # of penalties: 0
Net reward: 22, # of penalties: 0
Net reward: 24, # of penalties: 0
Net reward: 25, # of penalties: 0
Environment.act(): Primary agent has reached destination!
Net reward: 37, # of penalties: 0
Simulator.run(): Trial 65
Environment.reset(): Trial set up with start = (5, 5), destination = (6, 1), deadline = 25
RoutePlanner.route_to(): destination = (6, 1)
Net reward: 1, # of penalties: 0
Net reward: 2, # of penalties: 0
Net reward: 3, # of penalties: 0
Net reward: 4, # of penalties: 0
Net reward: 6, # of penalties: 0
Net reward: 8, # of penalties: 0
Net reward: 10, # of penalties: 0
Net reward: 11, # of penalties: 0
Net reward: 13, # of penalties: 0
Environment.act(): Primary agent has reached destination!
Net reward: 25, # of penalties: 0
Simulator.run(): Trial 66
Environment.reset(): Trial set up with start = (6, 1), destination = (2, 1), deadline = 20
RoutePlanner.route_to(): destination = (2, 1)
Net reward: 2, # of penalties: 0
Net reward: 4, # of penalties: 0
Net reward: 6, # of penalties: 0
Net reward: 8, # of penalties: 0
Net reward: 10, # of penalties: 0
Environment.act(): Primary agent has reached destination!
Net reward: 22, # of penalties: 0
Simulator.run(): Trial 67
Environment.reset(): Trial set up with start = (1, 6), destination = (7, 4), deadline = 40
RoutePlanner.route_to(): destination = (7, 4)
Net reward: 2, # of penalties: 0
Net reward: 3, # of penalties: 0
Net reward: 4, # of penalties: 0
Net reward: 5, # of penalties: 0
Net reward: 6, # of penalties: 0
Net reward: 8, # of penalties: 0
Net reward: 8, # of penalties: 0
Net reward: 10, # of penalties: 0
Net reward: 12, # of penalties: 0
Net reward: 14, # of penalties: 0
Net reward: 15, # of penalties: 0
Net reward: 16, # of penalties: 0
Net reward: 17, # of penalties: 0
Net reward: 18, # of penalties: 0
Net reward: 19, # of penalties: 0
Net reward: 21, # of penalties: 0
Net reward: 23, # of penalties: 0
Net reward: 25, # of penalties: 0
Environment.act(): Primary agent has reached destination!
Net reward: 37, # of penalties: 0
Simulator.run(): Trial 68
Environment.reset(): Trial set up with start = (6, 5), destination = (3, 6), deadline = 20
RoutePlanner.route_to(): destination = (3, 6)
Net reward: 2, # of penalties: 0
Net reward: 4, # of penalties: 0
Net reward: 6, # of penalties: 0
Environment.act(): Primary agent has reached destination!
Net reward: 18, # of penalties: 0
Simulator.run(): Trial 69
Environment.reset(): Trial set up with start = (6, 6), destination = (6, 1), deadline = 25
RoutePlanner.route_to(): destination = (6, 1)
Net reward: 2, # of penalties: 0
Net reward: 3, # of penalties: 0
Net reward: 4, # of penalties: 0
Net reward: 6, # of penalties: 0
Net reward: 8, # of penalties: 0
Net reward: 10, # of penalties: 0
Environment.act(): Primary agent has reached destination!
Net reward: 22, # of penalties: 0
Simulator.run(): Trial 70
Environment.reset(): Trial set up with start = (1, 5), destination = (7, 1), deadline = 50
RoutePlanner.route_to(): destination = (7, 1)
Net reward: 2, # of penalties: 0
Net reward: 3, # of penalties: 0
Net reward: 4, # of penalties: 0
Net reward: 6, # of penalties: 0
Net reward: 7, # of penalties: 0
Net reward: 8, # of penalties: 0
Net reward: 10, # of penalties: 0
Net reward: 12, # of penalties: 0
Net reward: 13, # of penalties: 0
Net reward: 14, # of penalties: 0
Net reward: 15, # of penalties: 0
Net reward: 16, # of penalties: 0
Net reward: 18, # of penalties: 0
Net reward: 20, # of penalties: 0
Net reward: 22, # of penalties: 0
Net reward: 24, # of penalties: 0
Net reward: 25, # of penalties: 0
Net reward: 26, # of penalties: 0
Net reward: 27, # of penalties: 0
Net reward: 28, # of penalties: 0
Net reward: 30, # of penalties: 0
Environment.act(): Primary agent has reached destination!
Net reward: 42, # of penalties: 0
Simulator.run(): Trial 71
Environment.reset(): Trial set up with start = (8, 1), destination = (4, 5), deadline = 40
RoutePlanner.route_to(): destination = (4, 5)
Net reward: 2, # of penalties: 0
Net reward: 3, # of penalties: 0
Net reward: 4, # of penalties: 0
Net reward: 5, # of penalties: 0
Net reward: 5, # of penalties: 0
Net reward: 6, # of penalties: 0
Net reward: 8, # of penalties: 0
Net reward: 10, # of penalties: 0
Net reward: 12, # of penalties: 0
Environment.act(): Primary agent has reached destination!
Net reward: 24, # of penalties: 0
Simulator.run(): Trial 72
Environment.reset(): Trial set up with start = (6, 5), destination = (5, 1), deadline = 25
RoutePlanner.route_to(): destination = (5, 1)
Net reward: 2, # of penalties: 0
Net reward: 4, # of penalties: 0
Net reward: 6, # of penalties: 0
Net reward: 7, # of penalties: 0
Net reward: 9, # of penalties: 0
Net reward: 10, # of penalties: 0
Net reward: 11, # of penalties: 0
Net reward: 12, # of penalties: 0
Net reward: 13, # of penalties: 0
Net reward: 14, # of penalties: 0
Net reward: 16, # of penalties: 0
Net reward: 18, # of penalties: 0
Net reward: 19, # of penalties: 0
Net reward: 20, # of penalties: 0
Net reward: 21, # of penalties: 0
Environment.act(): Primary agent has reached destination!
Net reward: 33, # of penalties: 0
Simulator.run(): Trial 73
Environment.reset(): Trial set up with start = (1, 3), destination = (6, 4), deadline = 30
RoutePlanner.route_to(): destination = (6, 4)
Net reward: 2, # of penalties: 0
Net reward: 4, # of penalties: 0
Net reward: 5, # of penalties: 0
Net reward: 6, # of penalties: 0
Net reward: 7, # of penalties: 0
Net reward: 9, # of penalties: 0
Net reward: 11, # of penalties: 0
Net reward: 12, # of penalties: 0
Net reward: 14, # of penalties: 0
Net reward: 16, # of penalties: 0
Net reward: 18, # of penalties: 0
Environment.act(): Primary agent has reached destination!
Net reward: 30, # of penalties: 0
Simulator.run(): Trial 74
Environment.reset(): Trial set up with start = (1, 3), destination = (5, 3), deadline = 20
RoutePlanner.route_to(): destination = (5, 3)
Net reward: 2, # of penalties: 0
Net reward: 4, # of penalties: 0
Net reward: 5, # of penalties: 0
Net reward: 6, # of penalties: 0
Net reward: 7, # of penalties: 0
Net reward: 9, # of penalties: 0
Net reward: 10, # of penalties: 0
Net reward: 11, # of penalties: 0
Net reward: 12, # of penalties: 0
Net reward: 12, # of penalties: 0
Net reward: 13, # of penalties: 0
Net reward: 14, # of penalties: 0
Net reward: 16, # of penalties: 0
Net reward: 17, # of penalties: 0
Net reward: 18, # of penalties: 0
Net reward: 19, # of penalties: 0
Environment.act(): Primary agent has reached destination!
Net reward: 31, # of penalties: 0
Simulator.run(): Trial 75
Environment.reset(): Trial set up with start = (3, 4), destination = (1, 6), deadline = 20
RoutePlanner.route_to(): destination = (1, 6)
Net reward: 2, # of penalties: 0
Net reward: 4, # of penalties: 0
Net reward: 6, # of penalties: 0
Environment.act(): Primary agent has reached destination!
Net reward: 18, # of penalties: 0
Simulator.run(): Trial 76
Environment.reset(): Trial set up with start = (8, 2), destination = (4, 6), deadline = 40
RoutePlanner.route_to(): destination = (4, 6)
Net reward: 2, # of penalties: 0
Net reward: 4, # of penalties: 0
Net reward: 5, # of penalties: 0
Net reward: 7, # of penalties: 0
Net reward: 8, # of penalties: 0
Net reward: 9, # of penalties: 0
Net reward: 11, # of penalties: 0
Net reward: 12, # of penalties: 0
Net reward: 14, # of penalties: 0
Net reward: 15, # of penalties: 0
Net reward: 16, # of penalties: 0
Net reward: 17, # of penalties: 0
Net reward: 19, # of penalties: 0
Net reward: 21, # of penalties: 0
Net reward: 22, # of penalties: 0
Environment.act(): Primary agent has reached destination!
Net reward: 34, # of penalties: 0
Simulator.run(): Trial 77
Environment.reset(): Trial set up with start = (6, 6), destination = (3, 3), deadline = 30
RoutePlanner.route_to(): destination = (3, 3)
Net reward: 1, # of penalties: 0
Net reward: 2, # of penalties: 0
Net reward: 3, # of penalties: 0
Net reward: 4, # of penalties: 0
Net reward: 6, # of penalties: 0
Net reward: 7, # of penalties: 0
Net reward: 8, # of penalties: 0
Net reward: 9, # of penalties: 0
Net reward: 11, # of penalties: 0
Net reward: 13, # of penalties: 0
Net reward: 15, # of penalties: 0
Net reward: 16, # of penalties: 0
Net reward: 18, # of penalties: 0
Environment.act(): Primary agent has reached destination!
Net reward: 30, # of penalties: 0
Simulator.run(): Trial 78
Environment.reset(): Trial set up with start = (2, 5), destination = (5, 3), deadline = 25
RoutePlanner.route_to(): destination = (5, 3)
Net reward: 2, # of penalties: 0
Net reward: 3, # of penalties: 0
Net reward: 4, # of penalties: 0
Net reward: 6, # of penalties: 0
Net reward: 7, # of penalties: 0
Net reward: 9, # of penalties: 0
Net reward: 11, # of penalties: 0
Environment.act(): Primary agent has reached destination!
Net reward: 23, # of penalties: 0
Simulator.run(): Trial 79
Environment.reset(): Trial set up with start = (3, 4), destination = (8, 2), deadline = 35
RoutePlanner.route_to(): destination = (8, 2)
Net reward: 2, # of penalties: 0
Net reward: 4, # of penalties: 0
Net reward: 5, # of penalties: 0
Net reward: 6, # of penalties: 0
Net reward: 7, # of penalties: 0
Net reward: 9, # of penalties: 0
Net reward: 11, # of penalties: 0
Net reward: 12, # of penalties: 0
Net reward: 13, # of penalties: 0
Net reward: 15, # of penalties: 0
Net reward: 16, # of penalties: 0
Net reward: 17, # of penalties: 0
Net reward: 19, # of penalties: 0
Environment.act(): Primary agent has reached destination!
Net reward: 31, # of penalties: 0
Simulator.run(): Trial 80
Environment.reset(): Trial set up with start = (4, 3), destination = (8, 5), deadline = 30
RoutePlanner.route_to(): destination = (8, 5)
Net reward: 2, # of penalties: 0
Net reward: 3, # of penalties: 0
Net reward: 4, # of penalties: 0
Net reward: 5, # of penalties: 0
Net reward: 6, # of penalties: 0
Net reward: 8, # of penalties: 0
Net reward: 10, # of penalties: 0
Net reward: 11, # of penalties: 0
Net reward: 13, # of penalties: 0
Net reward: 15, # of penalties: 0
Environment.act(): Primary agent has reached destination!
Net reward: 27, # of penalties: 0
Simulator.run(): Trial 81
Environment.reset(): Trial set up with start = (7, 1), destination = (2, 3), deadline = 35
RoutePlanner.route_to(): destination = (2, 3)
Net reward: 1, # of penalties: 0
Net reward: 2, # of penalties: 0
Net reward: 3, # of penalties: 0
Net reward: 4, # of penalties: 0
Net reward: 6, # of penalties: 0
Net reward: 7, # of penalties: 0
Net reward: 8, # of penalties: 0
Net reward: 9, # of penalties: 0
Net reward: 10, # of penalties: 0
Net reward: 11, # of penalties: 0
Net reward: 13, # of penalties: 0
Net reward: 14, # of penalties: 0
Net reward: 16, # of penalties: 0
Net reward: 18, # of penalties: 0
Net reward: 20, # of penalties: 0
Net reward: 22, # of penalties: 0
Environment.act(): Primary agent has reached destination!
Net reward: 34, # of penalties: 0
Simulator.run(): Trial 82
Environment.reset(): Trial set up with start = (1, 2), destination = (8, 3), deadline = 40
RoutePlanner.route_to(): destination = (8, 3)
Net reward: 2, # of penalties: 0
Net reward: 3, # of penalties: 0
Net reward: 4, # of penalties: 0
Net reward: 5, # of penalties: 0
Net reward: 6, # of penalties: 0
Net reward: 8, # of penalties: 0
Net reward: 10, # of penalties: 0
Net reward: 11, # of penalties: 0
Net reward: 13, # of penalties: 0
Net reward: 15, # of penalties: 0
Net reward: 16, # of penalties: 0
Net reward: 17, # of penalties: 0
Net reward: 19, # of penalties: 0
Net reward: 20, # of penalties: 0
Net reward: 21, # of penalties: 0
Net reward: 22, # of penalties: 0
Net reward: 24, # of penalties: 0
Environment.act(): Primary agent has reached destination!
Net reward: 36, # of penalties: 0
Simulator.run(): Trial 83
Environment.reset(): Trial set up with start = (4, 6), destination = (1, 3), deadline = 30
RoutePlanner.route_to(): destination = (1, 3)
Net reward: 2, # of penalties: 0
Net reward: 4, # of penalties: 0
Net reward: 5, # of penalties: 0
Net reward: 6, # of penalties: 0
Net reward: 8, # of penalties: 0
Net reward: 10, # of penalties: 0
Net reward: 11, # of penalties: 0
Net reward: 12, # of penalties: 0
Net reward: 13, # of penalties: 0
Net reward: 15, # of penalties: 0
Environment.act(): Primary agent has reached destination!
Net reward: 27, # of penalties: 0
Simulator.run(): Trial 84
Environment.reset(): Trial set up with start = (8, 4), destination = (5, 6), deadline = 25
RoutePlanner.route_to(): destination = (5, 6)
Net reward: 2, # of penalties: 0
Net reward: 3, # of penalties: 0
Net reward: 4, # of penalties: 0
Net reward: 6, # of penalties: 0
Net reward: 7, # of penalties: 0
Net reward: 9, # of penalties: 0
Net reward: 11, # of penalties: 0
Net reward: 12, # of penalties: 0
Environment.act(): Primary agent has reached destination!
Net reward: 24, # of penalties: 0
Simulator.run(): Trial 85
Environment.reset(): Trial set up with start = (5, 4), destination = (8, 3), deadline = 20
RoutePlanner.route_to(): destination = (8, 3)
Net reward: 1, # of penalties: 0
Net reward: 2, # of penalties: 0
Net reward: 3, # of penalties: 0
Net reward: 4, # of penalties: 0
Net reward: 5, # of penalties: 0
Net reward: 7, # of penalties: 0
Net reward: 8, # of penalties: 0
Net reward: 9, # of penalties: 0
Net reward: 10, # of penalties: 0
Net reward: 11, # of penalties: 0
Net reward: 13, # of penalties: 0
Net reward: 15, # of penalties: 0
Environment.act(): Primary agent has reached destination!
Net reward: 27, # of penalties: 0
Simulator.run(): Trial 86
Environment.reset(): Trial set up with start = (4, 4), destination = (8, 4), deadline = 20
RoutePlanner.route_to(): destination = (8, 4)
Net reward: 1, # of penalties: 0
Net reward: 2, # of penalties: 0
Net reward: 3, # of penalties: 0
Net reward: 5, # of penalties: 0
Net reward: 7, # of penalties: 0
Net reward: 8, # of penalties: 0
Net reward: 9, # of penalties: 0
Net reward: 10, # of penalties: 0
Net reward: 11, # of penalties: 0
Net reward: 12, # of penalties: 0
Net reward: 14, # of penalties: 0
Environment.act(): Primary agent has reached destination!
Net reward: 26, # of penalties: 0
Simulator.run(): Trial 87
Environment.reset(): Trial set up with start = (3, 6), destination = (8, 2), deadline = 45
RoutePlanner.route_to(): destination = (8, 2)
Net reward: 1, # of penalties: 0
Net reward: 2, # of penalties: 0
Net reward: 3, # of penalties: 0
Net reward: 4, # of penalties: 0
Net reward: 5, # of penalties: 0
Net reward: 7, # of penalties: 0
Net reward: 9, # of penalties: 0
Net reward: 10, # of penalties: 0
Net reward: 12, # of penalties: 0
Net reward: 13, # of penalties: 0
Net reward: 14, # of penalties: 0
Net reward: 15, # of penalties: 0
Net reward: 17, # of penalties: 0
Net reward: 19, # of penalties: 0
Net reward: 20, # of penalties: 0
Net reward: 21, # of penalties: 0
Net reward: 23, # of penalties: 0
Net reward: 24, # of penalties: 0
Net reward: 25, # of penalties: 0
Net reward: 26, # of penalties: 0
Net reward: 28, # of penalties: 0
Net reward: 29, # of penalties: 0
Net reward: 30, # of penalties: 0
Net reward: 31, # of penalties: 0
Net reward: 33, # of penalties: 0
Net reward: 34, # of penalties: 0
Net reward: 35, # of penalties: 0
Environment.act(): Primary agent has reached destination!
Net reward: 47, # of penalties: 0
Simulator.run(): Trial 88
Environment.reset(): Trial set up with start = (7, 6), destination = (1, 6), deadline = 30
RoutePlanner.route_to(): destination = (1, 6)
Net reward: 2, # of penalties: 0
Net reward: 4, # of penalties: 0
Net reward: 6, # of penalties: 0
Net reward: 8, # of penalties: 0
Net reward: 10, # of penalties: 0
Net reward: 11, # of penalties: 0
Net reward: 12, # of penalties: 0
Net reward: 13, # of penalties: 0
Net reward: 15, # of penalties: 0
Net reward: 16, # of penalties: 0
Net reward: 17, # of penalties: 0
Net reward: 18, # of penalties: 0
Net reward: 20, # of penalties: 0
Net reward: 22, # of penalties: 0
Net reward: 24, # of penalties: 0
Net reward: 26, # of penalties: 0
Net reward: 28, # of penalties: 0
Environment.act(): Primary agent has reached destination!
Net reward: 40, # of penalties: 0
Simulator.run(): Trial 89
Environment.reset(): Trial set up with start = (7, 1), destination = (1, 2), deadline = 35
RoutePlanner.route_to(): destination = (1, 2)
Net reward: 1, # of penalties: 0
Net reward: 2, # of penalties: 0
Net reward: 3, # of penalties: 0
Net reward: 4, # of penalties: 0
Net reward: 6, # of penalties: 0
Net reward: 8, # of penalties: 0
Net reward: 10, # of penalties: 0
Net reward: 12, # of penalties: 0
Net reward: 14, # of penalties: 0
Net reward: 16, # of penalties: 0
Environment.act(): Primary agent has reached destination!
Net reward: 28, # of penalties: 0
Simulator.run(): Trial 90
Environment.reset(): Trial set up with start = (5, 1), destination = (1, 3), deadline = 30
RoutePlanner.route_to(): destination = (1, 3)
Net reward: 2, # of penalties: 0
Net reward: 3, # of penalties: 0
Net reward: 4, # of penalties: 0
Net reward: 5, # of penalties: 0
Net reward: 6, # of penalties: 0
Net reward: 8, # of penalties: 0
Net reward: 9, # of penalties: 0
Net reward: 10, # of penalties: 0
Net reward: 12, # of penalties: 0
Net reward: 13, # of penalties: 0
Net reward: 14, # of penalties: 0
Net reward: 15, # of penalties: 0
Net reward: 17, # of penalties: 0
Net reward: 19, # of penalties: 0
Environment.act(): Primary agent has reached destination!
Net reward: 31, # of penalties: 0
Simulator.run(): Trial 91
Environment.reset(): Trial set up with start = (8, 2), destination = (5, 1), deadline = 20
RoutePlanner.route_to(): destination = (5, 1)
Net reward: 2, # of penalties: 0
Net reward: 4, # of penalties: 0
Net reward: 6, # of penalties: 0
Net reward: 7, # of penalties: 0
Net reward: 9, # of penalties: 0
Net reward: 11, # of penalties: 0
Environment.act(): Primary agent has reached destination!
Net reward: 23, # of penalties: 0
Simulator.run(): Trial 92
Environment.reset(): Trial set up with start = (1, 4), destination = (5, 2), deadline = 30
RoutePlanner.route_to(): destination = (5, 2)
Net reward: 1, # of penalties: 0
Net reward: 2, # of penalties: 0
Net reward: 3, # of penalties: 0
Net reward: 4, # of penalties: 0
Net reward: 6, # of penalties: 0
Net reward: 7, # of penalties: 0
Net reward: 9, # of penalties: 0
Net reward: 10, # of penalties: 0
Net reward: 12, # of penalties: 0
Net reward: 13, # of penalties: 0
Net reward: 14, # of penalties: 0
Net reward: 15, # of penalties: 0
Net reward: 15, # of penalties: 0
Net reward: 16, # of penalties: 0
Net reward: 17, # of penalties: 0
Net reward: 19, # of penalties: 0
Net reward: 21, # of penalties: 0
Net reward: 22, # of penalties: 0
Net reward: 23, # of penalties: 0
Net reward: 24, # of penalties: 0
Net reward: 26, # of penalties: 0
Environment.act(): Primary agent has reached destination!
Net reward: 38, # of penalties: 0
Simulator.run(): Trial 93
Environment.reset(): Trial set up with start = (3, 2), destination = (8, 2), deadline = 25
RoutePlanner.route_to(): destination = (8, 2)
Net reward: 2, # of penalties: 0
Net reward: 4, # of penalties: 0
Net reward: 6, # of penalties: 0
Net reward: 7, # of penalties: 0
Net reward: 8, # of penalties: 0
Net reward: 9, # of penalties: 0
Net reward: 11, # of penalties: 0
Net reward: 12, # of penalties: 0
Net reward: 13, # of penalties: 0
Net reward: 14, # of penalties: 0
Net reward: 16, # of penalties: 0
Net reward: 18, # of penalties: 0
Environment.act(): Primary agent has reached destination!
Net reward: 30, # of penalties: 0
Simulator.run(): Trial 94
Environment.reset(): Trial set up with start = (8, 2), destination = (2, 5), deadline = 45
RoutePlanner.route_to(): destination = (2, 5)
Net reward: 2, # of penalties: 0
Net reward: 4, # of penalties: 0
Net reward: 5, # of penalties: 0
Net reward: 6, # of penalties: 0
Net reward: 8, # of penalties: 0
Net reward: 9, # of penalties: 0
Net reward: 10, # of penalties: 0
Net reward: 11, # of penalties: 0
Net reward: 13, # of penalties: 0
Net reward: 15, # of penalties: 0
Net reward: 16, # of penalties: 0
Net reward: 17, # of penalties: 0
Net reward: 19, # of penalties: 0
Net reward: 20, # of penalties: 0
Net reward: 21, # of penalties: 0
Net reward: 23, # of penalties: 0
Net reward: 24, # of penalties: 0
Net reward: 25, # of penalties: 0
Net reward: 26, # of penalties: 0
Net reward: 27, # of penalties: 0
Net reward: 29, # of penalties: 0
Net reward: 30, # of penalties: 0
Net reward: 31, # of penalties: 0
Net reward: 32, # of penalties: 0
Environment.act(): Primary agent has reached destination!
Net reward: 44, # of penalties: 0
Simulator.run(): Trial 95
Environment.reset(): Trial set up with start = (4, 4), destination = (8, 6), deadline = 30
RoutePlanner.route_to(): destination = (8, 6)
Net reward: 2, # of penalties: 0
Net reward: 4, # of penalties: 0
Net reward: 5, # of penalties: 0
Net reward: 6, # of penalties: 0
Net reward: 7, # of penalties: 0
Net reward: 9, # of penalties: 0
Net reward: 10, # of penalties: 0
Net reward: 11, # of penalties: 0
Net reward: 13, # of penalties: 0
Net reward: 14, # of penalties: 0
Net reward: 15, # of penalties: 0
Net reward: 16, # of penalties: 0
Net reward: 18, # of penalties: 0
Net reward: 20, # of penalties: 0
Net reward: 22, # of penalties: 0
Environment.act(): Primary agent has reached destination!
Net reward: 34, # of penalties: 0
Simulator.run(): Trial 96
Environment.reset(): Trial set up with start = (6, 3), destination = (2, 4), deadline = 25
RoutePlanner.route_to(): destination = (2, 4)
Net reward: 2, # of penalties: 0
Net reward: 4, # of penalties: 0
Net reward: 6, # of penalties: 0
Net reward: 7, # of penalties: 0
Net reward: 8, # of penalties: 0
Net reward: 9, # of penalties: 0
Net reward: 11, # of penalties: 0
Environment.act(): Primary agent has reached destination!
Net reward: 23, # of penalties: 0
Simulator.run(): Trial 97
Environment.reset(): Trial set up with start = (6, 6), destination = (3, 3), deadline = 30
RoutePlanner.route_to(): destination = (3, 3)
Net reward: 2, # of penalties: 0
Net reward: 4, # of penalties: 0
Net reward: 6, # of penalties: 0
Net reward: 8, # of penalties: 0
Net reward: 9, # of penalties: 0
Net reward: 10, # of penalties: 0
Net reward: 12, # of penalties: 0
Environment.act(): Primary agent has reached destination!
Net reward: 24, # of penalties: 0
Simulator.run(): Trial 98
Environment.reset(): Trial set up with start = (7, 1), destination = (2, 1), deadline = 25
RoutePlanner.route_to(): destination = (2, 1)
Net reward: 2, # of penalties: 0
Net reward: 4, # of penalties: 0
Net reward: 6, # of penalties: 0
Net reward: 8, # of penalties: 0
Net reward: 9, # of penalties: 0
Net reward: 10, # of penalties: 0
Net reward: 11, # of penalties: 0
Net reward: 12, # of penalties: 0
Net reward: 12, # of penalties: 0
Net reward: 13, # of penalties: 0
Net reward: 15, # of penalties: 0
Net reward: 16, # of penalties: 0
Environment.act(): Primary agent has reached destination!
Net reward: 28, # of penalties: 0
Simulator.run(): Trial 99
Environment.reset(): Trial set up with start = (1, 3), destination = (4, 2), deadline = 20
RoutePlanner.route_to(): destination = (4, 2)
Net reward: 2, # of penalties: 0
Net reward: 3, # of penalties: 0
Net reward: 4, # of penalties: 0
Net reward: 5, # of penalties: 0
Net reward: 7, # of penalties: 0
Net reward: 8, # of penalties: 0
Net reward: 10, # of penalties: 0
Environment.act(): Primary agent has reached destination!
Net reward: 22, # of penalties: 0
